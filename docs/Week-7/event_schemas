Event Schemas (7 Critical Types)
Code Submission
json{
  "event_type": "code_submission",
  "timestamp": "2025-11-26T10:30:00Z",
  "user_id": "user_001",
  "problem_id": "two-sum",
  "user_code": "def two_sum(nums, target): ...",
  "language": "python"
}
Analysis Response
json{
  "event_type": "analysis_response",
  "submission_id": "sub_abc12345",
  "all_tests_passed": false,
  "test_results": [{"test_name": "Test 1", "passed": true, ...}],
  "detected_patterns": [
    {"pattern_type": "edge_case_missing", "severity": "high"}
  ],
  "time_complexity": "O(nÂ²)",
  "execution_time_ms": 45.2
}
Progress Update
json{
  "event_type": "progress_update",
  "user_id": "user_001",
  "detected_patterns": ["edge_case_missing"],
  "solved_correctly": false,
  "updated_weaknesses": [
    {"pattern_type": "edge_case_missing", "mastery_score": 40.0, "trend": "declining"}
  ]
}
Recommendation Request/Response
json// Request
{"event_type": "recommendation_request", "user_id": "user_001", "difficulty_level": "medium"}

// Response
{
  "recommended_problem": {
    "problem_id": "valid-parentheses",
    "difficulty": "medium",
    "target_patterns": ["edge_case_missing"]
  },
  "recommendation_reason": "Targets your weakest area: 40/100 mastery"
}
Error Event
json{
  "event_type": "error",
  "error_type": "api_error",
  "message": "Gemini API rate limit exceeded",
  "component": "agent",
  "stack_trace": "..."
}
```

**Validation Rules:**
- Timestamps: ISO 8601 (`YYYY-MM-DDTHH:MM:SSZ`)
- User IDs: `^user_[0-9]+$`
- Problem IDs: lowercase with hyphens
- Mastery scores: 0-100
- Complexity: `O(...)` format

---

## 3. Smoke Test Results

**17/17 tests passed** in 0.38s

| Test Category | Pass/Fail | Evidence |
|--------------|-----------|----------|
| End-to-end workflow | âœ… | All 3 functions chain correctly |
| Function 1 (analyze) | âœ… | 5/5 tests pass |
| Function 2 (recommend) | âœ… | 4/4 tests pass |
| Function 3 (track) | âœ… | 5/5 tests pass |
| Pydantic validation | âœ… | All models validate |
| Error handling | âœ… | Graceful fallbacks |
| Performance | âœ… | All <50ms |
| Gemini integration | âœ… | Function calling works |

**Coverage:** 94% tools.py, 100% models.py, 72% agent.py

---

## 4. Performance Baseline

### Latency (25 requests/function)
| Metric | analyze_code | recommend | track | Target | Status |
|--------|-------------|-----------|-------|--------|--------|
| p50 | 45ms | 12ms | 8ms | <500ms | âœ… |
| p95 | 51ms | 14ms | 9ms | <1s | âœ… |
| p99 | 55ms | 15ms | 10ms | <2s | âœ… |

### Token Usage & Cost
- Input: 300-500 tokens
- Output: 150-300 tokens
- **Cost per request: $0.000032**
- **100 users/day: $0.96/month**
- **1,000 users/day: $9.60/month**

### Bottlenecks
- **Current:** Pattern detection (45ms) - not critical
- **Future (Week 7):** Judge0 API (500-2000ms) - will cache identical submissions
- **Week 8+:** Database queries - will add indexing

---

## 5. Hypothesis Validation

**Hypothesis:** Rule-based pattern detection (regex, counting loops) can identify 3/5 common weaknesses.

**Test Set:** 20 "Two Sum" solutions (5 edge case issues, 5 nested loops, 5 wrong data structure, 5 clean)

**Results:**
| Pattern | Precision | Recall | F1 |
|---------|-----------|--------|-----|
| edge_case_missing | 100% (5/5) | 80% (4/5) | 88.9% |
| suboptimal_time | 80% (4/5) | 100% (4/4) | 88.9% |
| wrong_data_structure | 60% (3/5) | 100% (3/3) | 75.0% |
| **Overall** | **80%** | **93%** | **86%** |

**False Positives:** 3 (flagged list as wrong data structure when appropriate)  
**False Negatives:** 1 (missed "if arr:" edge case pattern)

**Conclusion:** âœ… Hypothesis confirmed. 86% F1 exceeds 60% bar. Rule-based sufficient for MVP. ML classifier planned Week 12+.

**Action Items:**
- Expand edge case regex to include "if arr:", "if len(arr)==0"
- Improve data structure heuristic to check problem requirements
- Add AST parsing for complexity (Week 8)

---

## 6. Readiness Assessment

### Can handle 5-20x scale?
**Yes** for Week 8. Current: 46ms @ 50 req/day. At 20x (1,000 req/day): ~60ms. Gemini has no rate limits at our tier.

### Error handlers robust?
**Mostly.** Current: try-catch blocks, Pydantic validation, fallbacks. **Missing:** retry logic, timeouts. **Action:** Add max_retries=3 + exponential backoff before Week 8.

### Cost sustainable?
**Yes for beta.** With Judge0 (Week 7): 100 users = $390/mo. 1,000 users = $3,610/mo (need self-hosted Judge0).

### Must fix before Week 8:
1. âš ï¸ **No retry logic** - Add max_retries=3, exponential backoff (CRITICAL)
2. âš ï¸ **No timeouts** - Add 5s timeout decorator (CRITICAL)
3. ðŸ“… **Judge0 integration** - Complete by Nov 27 (HIGH)
4. ðŸ“… **PostgreSQL** - Schema Week 8, implement Week 9 (MEDIUM)

### Readiness Score: **8.3/10** âœ… Ready with fixes

---

## Test Output Summary
```
17 passed in 0.38s
- analyze_code: 42.5ms avg
- recommend: 11.2ms avg  
- track: 7.9ms avg
Coverage: 94% tools, 100% models, 72% agent
Hypothesis Validation Data (20 solutions)

TP (True Positive): 12
FP (False Positive): 3
FN (False Negative): 1
TN (True Negative): 4
Accuracy: 80% | F1: 86%
